{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-09T10:27:09.943158Z","iopub.execute_input":"2021-08-09T10:27:09.943592Z","iopub.status.idle":"2021-08-09T10:27:29.736061Z","shell.execute_reply.started":"2021-08-09T10:27:09.943498Z","shell.execute_reply":"2021-08-09T10:27:29.734774Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.2.tar.gz (23 kB)\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20210108)\nRequirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.23)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (8.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=272447 sha256=524493c3d8ac1143503b4121e80082969428c1acc25094242bb9e3dfa68314a0\n  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.2\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from pycocotools.coco import COCO\nimport os\nfrom glob import glob\nimport pydicom\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap \nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms\nimport numpy as np\nfrom tqdm import tqdm_notebook as tqdm\nfrom numpy import transpose\nimport math\nfrom math import log, pi, sqrt\nfrom functools import partial\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\nimport PIL\n  \nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:27:29.740368Z","iopub.execute_input":"2021-08-09T10:27:29.740718Z","iopub.status.idle":"2021-08-09T10:27:32.720247Z","shell.execute_reply.started":"2021-08-09T10:27:29.740682Z","shell.execute_reply":"2021-08-09T10:27:32.718999Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"class CocoDataset(Dataset):\n    \"\"\"Low-Dose CT dataset.\"\"\"\n\n    def __init__(self,instance_path='../input/coco-2017-dataset/coco2017/annotations/instances_train2017.json',\n                 img_path='../input/coco-2017-dataset/coco2017/train2017',\n                 transform=None,):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.img_paths = img_path\n        self.coco=COCO(instance_path)\n        self.catIDs = self.coco.getCatIds()\n        # print(catIDs)\n        imgIds = []\n        for x in self.catIDs:\n            imgIds += self.coco.getImgIds(catIds = [x])\n        self.img_id = imgIds\n        self.len = len(imgIds)\n        print(self.len)\n        \n        if transform:\n            self.transform = transform\n        else:\n            self.transform = transforms.Compose([\n#                 transforms.Rescale(255),\n                transforms.ToTensor()\n            ])\n\n    def __len__(self):\n        return self.len\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img = self.coco.loadImgs(self.img_id[idx])[0]\n        image= plt.imread('{}/{}'.format(self.img_paths, img['file_name']))/255.0\n        mask = np.zeros((img['height'],img['width']))\n        annIds = self.coco.getAnnIds(imgIds=img['id'], catIds=self.catIDs, iscrowd=None)\n        anns = self.coco.loadAnns(annIds)\n        for i in range(len(anns)):\n            mask = np.maximum(self.coco.annToMask(anns[i]), mask)\n        mask = cv2.resize(mask, (64,64))\n        image = cv2.resize(image, (64,64)).astype(np.float32)\n        if(len(image.shape)==2):\n            image = cv2.merge([image, image, image])\n        mask = (mask > 0.5).astype(np.float32)\n        \n        if self.transform:\n            image = self.transform(image)\n            mask = self.transform(mask)\n            \n        sample = (image, mask)\n\n        return sample\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:27:32.723003Z","iopub.execute_input":"2021-08-09T10:27:32.723462Z","iopub.status.idle":"2021-08-09T10:27:32.740640Z","shell.execute_reply.started":"2021-08-09T10:27:32.723422Z","shell.execute_reply":"2021-08-09T10:27:32.739062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_set = CocoDataset()\nval_set = CocoDataset('../input/coco-2017-dataset/coco2017/annotations/instances_val2017.json', '../input/coco-2017-dataset/coco2017/val2017')","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:27:32.743581Z","iopub.execute_input":"2021-08-09T10:27:32.744126Z","iopub.status.idle":"2021-08-09T10:28:05.030209Z","shell.execute_reply.started":"2021-08-09T10:27:32.744078Z","shell.execute_reply":"2021-08-09T10:28:05.028910Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=29.62s)\ncreating index...\nindex created!\n342996\nloading annotations into memory...\nDone (t=1.03s)\ncreating index...\nindex created!\n14631\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 50\nWORKERS = 0\nSHUFFLE = True\ntrain_loader = DataLoader(train_set,  batch_size=BATCH_SIZE,\n                        shuffle=SHUFFLE, num_workers=WORKERS)\nval_loader = DataLoader(val_set,  batch_size=BATCH_SIZE,\n                        shuffle=SHUFFLE, num_workers=WORKERS)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:05.033682Z","iopub.execute_input":"2021-08-09T10:28:05.034021Z","iopub.status.idle":"2021-08-09T10:28:05.041886Z","shell.execute_reply.started":"2021-08-09T10:28:05.033991Z","shell.execute_reply":"2021-08-09T10:28:05.040832Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class DenseLayer(nn.Sequential):\n    def __init__(self, in_channels, growth_rate):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm2d(in_channels))\n        self.add_module('relu', nn.ReLU(True))\n        self.add_module('conv', nn.Conv2d(in_channels, growth_rate, kernel_size=3,\n                                          stride=1, padding=1, bias=True))\n        self.add_module('drop', nn.Dropout2d(0.2))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\nclass DenseBlock(nn.Module):\n    def __init__(self, in_channels, growth_rate, n_layers, upsample=False):\n        super().__init__()\n        self.upsample = upsample\n        self.layers = nn.ModuleList([DenseLayer(\n            in_channels + i*growth_rate, growth_rate)\n            for i in range(n_layers)])\n\n    def forward(self, x):\n        if self.upsample:\n            new_features = []\n            #we pass all previous activations into each dense layer normally\n            #But we only store each dense layer's output in the new_features array\n            for layer in self.layers:\n                out = layer(x)\n                x = torch.cat([x, out], 1)\n                new_features.append(out)\n            return torch.cat(new_features,1)\n        else:\n            for layer in self.layers:\n                out = layer(x)\n                x = torch.cat([x, out], 1) # 1 = channel axis\n            return x\n\n\nclass TransitionDown(nn.Sequential):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module('conv', nn.Conv2d(in_channels, in_channels,\n                                          kernel_size=1, stride=1,\n                                          padding=0, bias=True))\n        self.add_module('drop', nn.Dropout2d(0.2))\n        self.add_module('maxpool', nn.MaxPool2d(2))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\nclass TransitionUp(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.convTrans = nn.ConvTranspose2d(\n            in_channels=in_channels, out_channels=out_channels,\n            kernel_size=3, stride=2, padding=0, bias=True)\n\n    def forward(self, x, skip):\n        out = self.convTrans(x)\n        out = center_crop(out, skip.size(2), skip.size(3))\n        out = torch.cat([out, skip], 1)\n        return out\n\n\nclass Bottleneck(nn.Sequential):\n    def __init__(self, in_channels, growth_rate, n_layers):\n        super().__init__()\n        self.add_module('bottleneck', DenseBlock(\n            in_channels, growth_rate, n_layers, upsample=True))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\ndef center_crop(layer, max_height, max_width):\n    _, _, h, w = layer.size()\n    xy1 = (w - max_width) // 2\n    xy2 = (h - max_height) // 2\n    return layer[:, :, xy2:(xy2 + max_height), xy1:(xy1 + max_width)]\n\nclass FCDenseNet(nn.Module):\n    def __init__(self, in_channels=3, down_blocks=(5,5,5,5,5),\n                 up_blocks=(5,5,5,5,5), bottleneck_layers=5,\n                 growth_rate=16, out_chans_first_conv=48, n_classes=1):\n        super().__init__()\n        self.down_blocks = down_blocks\n        self.up_blocks = up_blocks\n        cur_channels_count = 0\n        skip_connection_channel_counts = []\n\n        ## First Convolution ##\n\n        self.add_module('firstconv', nn.Conv2d(in_channels=in_channels,\n                  out_channels=out_chans_first_conv, kernel_size=3,\n                  stride=1, padding=1, bias=True))\n        cur_channels_count = out_chans_first_conv\n\n        #####################\n        # Downsampling path #\n        #####################\n\n        self.denseBlocksDown = nn.ModuleList([])\n        self.transDownBlocks = nn.ModuleList([])\n        for i in range(len(down_blocks)):\n            self.denseBlocksDown.append(\n                DenseBlock(cur_channels_count, growth_rate, down_blocks[i]))\n            cur_channels_count += (growth_rate*down_blocks[i])\n            skip_connection_channel_counts.insert(0,cur_channels_count)\n            self.transDownBlocks.append(TransitionDown(cur_channels_count))\n\n        #####################\n        #     Bottleneck    #\n        #####################\n\n        self.add_module('bottleneck',Bottleneck(cur_channels_count,\n                                     growth_rate, bottleneck_layers))\n        prev_block_channels = growth_rate*bottleneck_layers\n        cur_channels_count += prev_block_channels\n\n        #######################\n        #   Upsampling path   #\n        #######################\n\n        self.transUpBlocks = nn.ModuleList([])\n        self.denseBlocksUp = nn.ModuleList([])\n        for i in range(len(up_blocks)-1):\n            self.transUpBlocks.append(TransitionUp(prev_block_channels, prev_block_channels))\n            cur_channels_count = prev_block_channels + skip_connection_channel_counts[i]\n\n            self.denseBlocksUp.append(DenseBlock(\n                cur_channels_count, growth_rate, up_blocks[i],\n                    upsample=True))\n            prev_block_channels = growth_rate*up_blocks[i]\n            cur_channels_count += prev_block_channels\n\n        ## Final DenseBlock ##\n\n        self.transUpBlocks.append(TransitionUp(\n            prev_block_channels, prev_block_channels))\n        cur_channels_count = prev_block_channels + skip_connection_channel_counts[-1]\n\n        self.denseBlocksUp.append(DenseBlock(\n            cur_channels_count, growth_rate, up_blocks[-1],\n                upsample=False))\n        cur_channels_count += growth_rate*up_blocks[-1]\n\n        ## Softmax ##\n\n        self.finalConv = nn.Conv2d(in_channels=cur_channels_count,\n               out_channels=n_classes, kernel_size=1, stride=1,\n                   padding=0, bias=True)\n        self.sig = nn.Sigmoid()\n    def forward(self, x):\n        out = self.firstconv(x)\n\n        skip_connections = []\n        for i in range(len(self.down_blocks)):\n            out = self.denseBlocksDown[i](out)\n            skip_connections.append(out)\n            out = self.transDownBlocks[i](out)\n\n        out = self.bottleneck(out)\n        for i in range(len(self.up_blocks)):\n            skip = skip_connections.pop()\n            out = self.transUpBlocks[i](out, skip)\n            out = self.denseBlocksUp[i](out)\n\n        out = self.finalConv(out)\n        out = self.sig(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:05.043843Z","iopub.execute_input":"2021-08-09T10:28:05.044296Z","iopub.status.idle":"2021-08-09T10:28:05.089025Z","shell.execute_reply.started":"2021-08-09T10:28:05.044253Z","shell.execute_reply":"2021-08-09T10:28:05.087749Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = FCDenseNet()\nif torch.cuda.is_available():\n    model = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:05.092951Z","iopub.execute_input":"2021-08-09T10:28:05.093328Z","iopub.status.idle":"2021-08-09T10:28:10.667031Z","shell.execute_reply.started":"2021-08-09T10:28:05.093297Z","shell.execute_reply":"2021-08-09T10:28:10.665940Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Binary cross entropy loss function\ncriterion = nn.BCELoss()\nif torch.cuda.is_available():\n    criterion = criterion.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:10.669492Z","iopub.execute_input":"2021-08-09T10:28:10.669814Z","iopub.status.idle":"2021-08-09T10:28:10.678983Z","shell.execute_reply.started":"2021-08-09T10:28:10.669768Z","shell.execute_reply":"2021-08-09T10:28:10.677669Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Adam Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:10.680959Z","iopub.execute_input":"2021-08-09T10:28:10.681571Z","iopub.status.idle":"2021-08-09T10:28:10.698053Z","shell.execute_reply.started":"2021-08-09T10:28:10.681525Z","shell.execute_reply":"2021-08-09T10:28:10.696718Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 6\n\nfor epoch in range(1, n_epochs+1):\n    # monitor training loss\n    train_loss = 0.0\n#     train the model\n    bar = tqdm(train_loader)\n    for data in bar:\n        img, mask = data\n        if torch.cuda.is_available():\n            img, mask = img.cuda(), mask.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass\n        outputs = model(img)\n        loss = criterion(outputs, mask)\n        # backward pass\n        loss.backward()\n        # optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()\n        bar.set_description(\"Processing %s\" % loss.item())\n    if epoch%2==0:\n        torch.save(model, \"./modelComplete\"+str(epoch))\n    valid_loss = 0.0\n    val_bar = tqdm(val_loader)\n    for data in val_bar:\n        \n        img, mask = data\n        if torch.cuda.is_available():\n            img, mask = img.cuda(), mask.cuda()\n        \n        target = model(img)\n       \n        loss = criterion(target,mask)\n        valid_loss += loss.item()\n        val_bar.set_description(\"Processing %s\" % loss.item())\n            \n    # print avg training statistics \n    train_loss = train_loss/len(train_loader)\n    valid_loss = valid_loss/len(val_loader)\n    print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss: {:.8f} \\t'.format(\n        epoch, \n        train_loss,valid_loss\n        ))","metadata":{"execution":{"iopub.status.busy":"2021-08-09T10:28:10.699918Z","iopub.execute_input":"2021-08-09T10:28:10.700388Z","iopub.status.idle":"2021-08-09T10:30:49.470272Z","shell.execute_reply.started":"2021-08-09T10:28:10.700344Z","shell.execute_reply":"2021-08-09T10:30:49.466846Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6860 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a94db1aa6248d7a8036db75ca31a73"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/293 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b9767015a9f4ef1a812700b92cc2319"}},"metadata":{}},{"name":"stdout","text":"torch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\ntorch.Size([50, 3, 64, 64])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-762cbcca1083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mval_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-539f6f9eb43f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mannIds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAnnIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miscrowd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'JpegImageFile' and 'float'"],"ename":"TypeError","evalue":"unsupported operand type(s) for /: 'JpegImageFile' and 'float'","output_type":"error"}]}]}